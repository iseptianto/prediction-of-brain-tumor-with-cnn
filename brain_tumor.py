# -*- coding: utf-8 -*-
"""brain tumor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aMkj2w9l6L_90hxul11A_xIU2BTuswUw

# **Import Library**
"""

!pip install wget # Install the wget library to download the dataset
import wget
import os
import zipfile

from PIL import Image
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
import cv2
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
import matplotlib.pyplot as plt
import io
from google.colab import files

"""# **Import Library Images**"""

def load_images(directory):
    images = []
    for filename in os.listdir(directory):

          img = Image.open(os.path.join(directory, filename))
          img = img.resize((224, 224))
          img = img.convert('RGB')
          img = np.array(img) / 255.0
          images.append(img)
    return images

tumor_images = load_images('/content/drive/MyDrive/data/yes')
no_tumor_images = load_images('/content/drive/MyDrive/data/no')

from google.colab import drive
drive.mount('/content/drive')

fig, axes = plt.subplots(2, 5, figsize=(20, 10))

for i in range(5):
	axes[0, i].imshow(tumor_images[i])
	axes[0, i].set_title('tumor_images')
	axes[0, i].axis('off')

for i in range(5):
	axes[1, i].imshow(no_tumor_images[i])
	axes[1, i].set_title('no_tumor_images')
	axes[1, i].axis('off')

plt.show()

"""# **Tpye Image**"""

type(tumor_images)
type(no_tumor_images)

len(tumor_images)

len(no_tumor_images)

tumor_images

no_tumor_images

def assign_labels(tumor_images, no_tumor_images):
	tumor_labels = np.ones(len(tumor_images))
	no_tumor_labels = np.zeros(len(no_tumor_images))
	return tumor_labels, no_tumor_labels
tumor_labels, no_tumor_labels = assign_labels(tumor_images, no_tumor_images)

"""# **Label No Tumor and Tumor**"""

tumor_labels

no_tumor_labels

"""# **Type New Labels**"""

type(tumor_labels)
type(no_tumor_labels)

data = tumor_images + no_tumor_images
labels = np.concatenate((tumor_labels, no_tumor_labels), axis=0)

data

labels

data[0].shape

x = np.array(data)
y = np.array(labels)

"""# **Split Train Test**"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2, random_state = 42)

train = tf.data.Dataset.from_tensor_slices((x_train, y_train))
test = tf.data.Dataset.from_tensor_slices((x_test, y_test))

for image, label in train.take(5):
	plt.figure()
	plt.imshow(image.numpy())
	plt.title('Label: {}'.format(label.numpy()))
	plt.axis('off')
	plt.show()

validation_size = int(0.1 * 210)
train = train.skip(validation_size)
val = train.take(validation_size)

BATCH_SIZE = 32
train = train.batch(BATCH_SIZE)
test = test.batch(BATCH_SIZE)
val = val.batch(BATCH_SIZE)

model = Sequential()

# Changed input_shape to (224, 224, 3) to match the actual image size
model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (224,224,3), padding='valid'))
model.add(MaxPooling2D((2,2)))
model.add(Flatten())
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train, validation_data = val, epochs = 20, verbose = 1)

"""# **Evaluation**"""

evaluation = model.evaluate(test)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Accuracy', 'Val Accuracy'], loc = 'upper right')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss', 'Val Loss'], loc = 'upper right')
plt.title('Loss Progress')
plt.xlabel('epochs')
plt.ylabel('Loss')
plt.show()

"""# **Save DATA Model with H5**"""

model.save("/content/drive/MyDrive/data/brain_tumor.h5")

"""# **Updated Code (Using Pickle)**"""

import pickle

# Save the model as a pickle file
with open("/content/drive/MyDrive/data/brain_tumor.pkl", "wb") as f:
    pickle.dump(model, f)

def load_uploaded_image(image_bytes):
    img = Image.open(io.BytesIO(image_bytes))
    img = img.resize((224, 224))  # Changed the height to 224
    img_array = np.array(img)
    img_array = img_array / 255.0
    return img_array

def predict_image(image_bytes):
    img_array = load_uploaded_image(image_bytes)
    img_array = np.expand_dims(img_array, axis=0)
    prediction = model.predict(img_array)
    if prediction[0][0] > 0.5:
        return "Tumor detected"
    else:
        return "No tumor detected"

uploaded = files.upload()
file_name = list(uploaded.keys())[0]
image_bytes = uploaded[file_name]
img = Image.open(io.BytesIO(image_bytes))

plt.imshow(img)
plt.axis('off')
plt.show()

result = predict_image(image_bytes)
print(result)

"""# **install Requirement**"""

!pip install session-info

pip freeze > requirements.txt